{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-28d3b588298a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir = \"'data/processed_data/\"\n",
    "#Transformation for image\n",
    "transform_ori = transforms.Compose([transforms.RandomResizedCrop(64),   #create 64x64 image\n",
    "                                    transforms.RandomHorizontalFlip(),    #flipping the image horizontally\n",
    "                                    transforms.ToTensor(),                 #convert the image to a Tensor\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                         std=[0.229, 0.224, 0.225])])  #normalize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load our dataset\n",
    "train_dataset = datasets.ImageFolder(root =Dir+\"/\"+\"Training\",\n",
    "                                     transform = transform_ori)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root = Dir+\"/\"+\"Testing\",\n",
    "                                    transform = transform_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the dataset iterable\n",
    "batch_size = 10\n",
    "train_load = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "                                         batch_size = batch_size,pin_memory=True,\n",
    "                                         shuffle = True)\n",
    "\n",
    "test_load = torch.utils.data.DataLoader(dataset = test_dataset, \n",
    "                                         batch_size = batch_size,pin_memory=True,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to C:\\Users\\usappidi/.cache\\torch\\hub\\checkpoints\\densenet201-c1103571.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866e5bbc6d42463a9ba8323c907b831c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81131730.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "#Load the DenseNet\n",
    "model_conv = torchvision.models.densenet201(pretrained=True)\n",
    "#Freeze all layers in the network  \n",
    "for param in model_conv.parameters():  \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of inputs of the last layer (or number of neurons in the layer preceeding the last layer)\n",
    "num_ftrs = model_conv.classifier.in_features\n",
    "\n",
    "#Reconstruct the last layer (output layer) to have only two classes \n",
    "model_conv.classifier = nn.Linear(num_ftrs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9) #Try Adam optimizer for better accuracy: optim.Adam(model_conv.parameters(), lr=0.001)\n",
    "\n",
    "#Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.5504, Train Accuracy: 490%, Time: 380.83s\n",
      "Epoch [2/50], Loss: 0.8273, Train Accuracy: 493%, Time: 366.11s\n",
      "Epoch [3/50], Loss: 0.7518, Train Accuracy: 498%, Time: 373.18s\n",
      "Epoch [4/50], Loss: 0.5264, Train Accuracy: 483%, Time: 518.87s\n",
      "Epoch [5/50], Loss: 0.5761, Train Accuracy: 485%, Time: 727.29s\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "import time\n",
    "num_epochs = 50\n",
    "for epoch in range (num_epochs):\n",
    "    start = time.time()\n",
    "    exp_lr_scheduler.step()\n",
    "    #Reset the correct to 0 after passing through all the dataset\n",
    "    correct = 0\n",
    "    for i, (inputs, labels) in enumerate(train_load):\n",
    "        images = Variable(inputs)\n",
    "        labels = Variable(labels)\n",
    "        if torch.cuda.is_available():\n",
    "            images = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_conv(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        _, predicted = torch.max(outputs, 1) \n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "    train_acc = 100 * correct // len(test_dataset)\n",
    "    stop = time.time()\n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}, Train Accuracy: {}%, Time: {:.2f}s'\n",
    "            .format(epoch+1, num_epochs, loss.item(), train_acc, stop-start))\n",
    "    \n",
    "\n",
    "classes = ('glioma_tumor', 'meningioma_tumor','no_tumor','pituitary_tumor')\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_load:\n",
    "        images, labels = data\n",
    "        outputs = model_conv(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(10):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_load:\n",
    "        images, labels = data\n",
    "        outputs = model_conv(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
