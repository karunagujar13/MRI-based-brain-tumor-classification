{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model - Uses NASNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses :\n",
    "    1. NASNet as the base architecture \n",
    "    2. Batch size =64 and 150 epochs. \n",
    "    3. Uses processed (Histogram equalized) data \n",
    "    4. Without balanced weights.\n",
    "    5. Uses LR scheduler step decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "#from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_ROWS, IMG_COLS = 224, 224\n",
    "INPUT_SHAPE=(224, 224, 3)\n",
    "PATH = 'data/processed_data/'\n",
    "TRAIN_DATA_PATH = os.path.join(PATH, 'Training')\n",
    "TEST_DATA_PATH = os.path.join(PATH, 'Testing')\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 150\n",
    "CLASS_MODE = 'categorical'\n",
    "COLOR_MODE = 'rgb'\n",
    "SAVE_FORMAT = 'png'\n",
    "#40, 100 - 61\n",
    "#64 batch size, 150 epoch ---62.43\n",
    "#128, 150 -- 60.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_dir_list =np.sort(os.listdir(TRAIN_DATA_PATH))\n",
    "data_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_dir_list_Test =np.sort(os.listdir(TEST_DATA_PATH))\n",
    "data_dir_list_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    rotation_range=50,\n",
    "    brightness_range=[0.2,0.8],\n",
    "    vertical_flip=True, \n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=[0.5,0.8],\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2298 images belonging to 4 classes.\n",
      "Found 573 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        TRAIN_DATA_PATH,\n",
    "        target_size=(IMG_ROWS, IMG_COLS), \n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=CLASS_MODE,\n",
    "        color_mode=COLOR_MODE, \n",
    "        shuffle=True,   \n",
    "        save_format=SAVE_FORMAT, \n",
    "        subset=\"training\")\n",
    "\n",
    "\n",
    "val_generator = train_data_gen.flow_from_directory(\n",
    "    TRAIN_DATA_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    color_mode=COLOR_MODE, \n",
    "    shuffle=True,   \n",
    "    save_format=SAVE_FORMAT, \n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2298"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glioma_tumor': 0, 'meningioma_tumor': 1, 'no_tumor': 2, 'pituitary_tumor': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DATA_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    color_mode=COLOR_MODE, \n",
    "    shuffle = False,\n",
    "    seed=None,  \n",
    "    save_format=SAVE_FORMAT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_nasnet_model():\n",
    "    \n",
    "    # Base model, with weights pre-trained on ImageNet.\n",
    "    base_model = NASNetMobile(INPUT_SHAPE, weights='imagenet', include_top=False)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.8\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=False)\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'categorical_crossentropy',\n",
    "        optimizer = optimizer,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "   initial_lrate = 0.1\n",
    "   drop = 0.5\n",
    "   epochs_drop = 10.0\n",
    "   lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate\n",
    "\n",
    "lr_scheduler =keras.callbacks.LearningRateScheduler(step_decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks_list  = [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 1/150\n",
      "36/36 [==============================] - 100s 3s/step - loss: 2.9486 - accuracy: 0.4843 - val_loss: 2.0810 - val_accuracy: 0.4660\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 2/150\n",
      "36/36 [==============================] - 102s 3s/step - loss: 1.8131 - accuracy: 0.5949 - val_loss: 1.8822 - val_accuracy: 0.5899\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 3/150\n",
      "36/36 [==============================] - 98s 3s/step - loss: 1.7149 - accuracy: 0.6014 - val_loss: 1.5025 - val_accuracy: 0.6387\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 4/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 1.6980 - accuracy: 0.6140 - val_loss: 1.1020 - val_accuracy: 0.6422\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 5/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.6575 - accuracy: 0.6101 - val_loss: 1.0390 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 6/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 1.5655 - accuracy: 0.6319 - val_loss: 1.5559 - val_accuracy: 0.5951\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 7/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 1.4964 - accuracy: 0.6458 - val_loss: 1.4580 - val_accuracy: 0.5742\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 8/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 1.5924 - accuracy: 0.6314 - val_loss: 1.1075 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 9/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.5417 - accuracy: 0.6275 - val_loss: 3.4021 - val_accuracy: 0.5305\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 10/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.5370 - accuracy: 0.6601 - val_loss: 1.2890 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 11/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.2386 - accuracy: 0.6623 - val_loss: 0.8590 - val_accuracy: 0.6894\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 12/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.1192 - accuracy: 0.6741 - val_loss: 0.7895 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 13/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.1561 - accuracy: 0.6514 - val_loss: 0.8316 - val_accuracy: 0.6771\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 14/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 1.2184 - accuracy: 0.6671 - val_loss: 0.8590 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 15/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.0726 - accuracy: 0.6736 - val_loss: 0.8524 - val_accuracy: 0.6719\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 16/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.0988 - accuracy: 0.6715 - val_loss: 1.0139 - val_accuracy: 0.6440\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 17/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 1.0034 - accuracy: 0.6867 - val_loss: 0.9102 - val_accuracy: 0.6702\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 18/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.2376 - accuracy: 0.6554 - val_loss: 0.8541 - val_accuracy: 0.6928\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 19/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.0797 - accuracy: 0.6710 - val_loss: 0.7490 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 20/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.9716 - accuracy: 0.6932 - val_loss: 1.0583 - val_accuracy: 0.5829\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 21/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.9036 - accuracy: 0.6941 - val_loss: 0.9283 - val_accuracy: 0.6440\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 22/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8840 - accuracy: 0.6889 - val_loss: 0.7088 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 23/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8630 - accuracy: 0.6932 - val_loss: 0.6880 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 24/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.8333 - accuracy: 0.7115 - val_loss: 0.7022 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 25/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.8283 - accuracy: 0.7119 - val_loss: 0.8369 - val_accuracy: 0.6492\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 26/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.9161 - accuracy: 0.6950 - val_loss: 0.8338 - val_accuracy: 0.6771\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 27/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7929 - accuracy: 0.7193 - val_loss: 0.6771 - val_accuracy: 0.7155\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 28/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8215 - accuracy: 0.7058 - val_loss: 0.8088 - val_accuracy: 0.6928\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 29/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.7779 - accuracy: 0.7071 - val_loss: 0.6537 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 30/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7589 - accuracy: 0.7158 - val_loss: 0.6765 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 31/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7811 - accuracy: 0.7224 - val_loss: 0.7201 - val_accuracy: 0.6928\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 32/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7740 - accuracy: 0.7228 - val_loss: 0.6993 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 33/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.7447 - accuracy: 0.7119 - val_loss: 0.6978 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 34/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.7632 - accuracy: 0.7145 - val_loss: 0.7533 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 35/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.7495 - accuracy: 0.7198 - val_loss: 0.7590 - val_accuracy: 0.6876\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 36/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.7204 - accuracy: 0.7419 - val_loss: 0.6894 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 37/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.7190 - accuracy: 0.7215 - val_loss: 0.7281 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 38/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.7286 - accuracy: 0.7306 - val_loss: 0.7514 - val_accuracy: 0.6876\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 39/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7253 - accuracy: 0.7250 - val_loss: 0.6967 - val_accuracy: 0.7312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 40/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7311 - accuracy: 0.7237 - val_loss: 0.6737 - val_accuracy: 0.7033\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 41/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7005 - accuracy: 0.7232 - val_loss: 0.6586 - val_accuracy: 0.7277\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 42/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7074 - accuracy: 0.7315 - val_loss: 0.6909 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 43/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7048 - accuracy: 0.7250 - val_loss: 0.6876 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 44/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7065 - accuracy: 0.7289 - val_loss: 0.6981 - val_accuracy: 0.6824\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 45/150\n",
      "36/36 [==============================] - 105s 3s/step - loss: 0.6456 - accuracy: 0.7376 - val_loss: 0.6651 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 46/150\n",
      "36/36 [==============================] - 102s 3s/step - loss: 0.6937 - accuracy: 0.7267 - val_loss: 0.7164 - val_accuracy: 0.6963\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 47/150\n",
      "36/36 [==============================] - 99s 3s/step - loss: 0.6921 - accuracy: 0.7385 - val_loss: 0.7425 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 48/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6894 - accuracy: 0.7372 - val_loss: 0.6944 - val_accuracy: 0.7155\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 49/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6856 - accuracy: 0.7311 - val_loss: 0.7154 - val_accuracy: 0.6911\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 50/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.7073 - accuracy: 0.7306 - val_loss: 0.6811 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 51/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6691 - accuracy: 0.7337 - val_loss: 0.6894 - val_accuracy: 0.6928\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 52/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6610 - accuracy: 0.7498 - val_loss: 0.6988 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 53/150\n",
      "36/36 [==============================] - 98s 3s/step - loss: 0.6783 - accuracy: 0.7376 - val_loss: 0.7067 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 54/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6907 - accuracy: 0.7459 - val_loss: 0.6493 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 55/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6765 - accuracy: 0.7341 - val_loss: 0.6576 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 56/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6799 - accuracy: 0.7376 - val_loss: 0.6878 - val_accuracy: 0.6981\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 57/150\n",
      "36/36 [==============================] - 99s 3s/step - loss: 0.6778 - accuracy: 0.7454 - val_loss: 0.7025 - val_accuracy: 0.6963\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 58/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6594 - accuracy: 0.7324 - val_loss: 0.6747 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 59/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6760 - accuracy: 0.7467 - val_loss: 0.6693 - val_accuracy: 0.7190\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 60/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6950 - accuracy: 0.7272 - val_loss: 0.6736 - val_accuracy: 0.7260\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 61/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6770 - accuracy: 0.7424 - val_loss: 0.6866 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 62/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6822 - accuracy: 0.7319 - val_loss: 0.6789 - val_accuracy: 0.7190\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 63/150\n",
      "36/36 [==============================] - 98s 3s/step - loss: 0.7009 - accuracy: 0.7319 - val_loss: 0.6559 - val_accuracy: 0.7033\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 64/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6582 - accuracy: 0.7398 - val_loss: 0.6986 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 65/150\n",
      "36/36 [==============================] - 98s 3s/step - loss: 0.6506 - accuracy: 0.7511 - val_loss: 0.6865 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 66/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6540 - accuracy: 0.7446 - val_loss: 0.6720 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 67/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6584 - accuracy: 0.7589 - val_loss: 0.6907 - val_accuracy: 0.7033\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 68/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6649 - accuracy: 0.7424 - val_loss: 0.6515 - val_accuracy: 0.7260\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 69/150\n",
      "36/36 [==============================] - 105s 3s/step - loss: 0.6866 - accuracy: 0.7411 - val_loss: 0.6555 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 70/150\n",
      "36/36 [==============================] - 102s 3s/step - loss: 0.6684 - accuracy: 0.7380 - val_loss: 0.6912 - val_accuracy: 0.7190\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 71/150\n",
      "36/36 [==============================] - 99s 3s/step - loss: 0.6588 - accuracy: 0.7537 - val_loss: 0.6876 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 72/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6595 - accuracy: 0.7446 - val_loss: 0.6618 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 73/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6776 - accuracy: 0.7428 - val_loss: 0.6776 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 74/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6607 - accuracy: 0.7406 - val_loss: 0.6962 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 75/150\n",
      "36/36 [==============================] - 103s 3s/step - loss: 0.6829 - accuracy: 0.7406 - val_loss: 0.6649 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 76/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6653 - accuracy: 0.7428 - val_loss: 0.7138 - val_accuracy: 0.6894\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 77/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6947 - accuracy: 0.7258 - val_loss: 0.6892 - val_accuracy: 0.7155\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 96s 3s/step - loss: 0.6429 - accuracy: 0.7476 - val_loss: 0.7013 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 79/150\n",
      "36/36 [==============================] - 100s 3s/step - loss: 0.6662 - accuracy: 0.7415 - val_loss: 0.6920 - val_accuracy: 0.6998\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 80/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6773 - accuracy: 0.7389 - val_loss: 0.7242 - val_accuracy: 0.6981\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 81/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6810 - accuracy: 0.7511 - val_loss: 0.6907 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 82/150\n",
      "36/36 [==============================] - 103s 3s/step - loss: 0.6258 - accuracy: 0.7581 - val_loss: 0.6981 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 83/150\n",
      "36/36 [==============================] - 105s 3s/step - loss: 0.6792 - accuracy: 0.7411 - val_loss: 0.6791 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 84/150\n",
      "36/36 [==============================] - 115s 3s/step - loss: 0.6903 - accuracy: 0.7289 - val_loss: 0.6668 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 85/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6325 - accuracy: 0.7646 - val_loss: 0.6830 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 86/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6710 - accuracy: 0.7372 - val_loss: 0.7003 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 87/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6545 - accuracy: 0.7515 - val_loss: 0.6537 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 88/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6684 - accuracy: 0.7459 - val_loss: 0.6500 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 89/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6846 - accuracy: 0.7289 - val_loss: 0.6999 - val_accuracy: 0.6998\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 90/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6899 - accuracy: 0.7341 - val_loss: 0.6347 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 91/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6493 - accuracy: 0.7502 - val_loss: 0.6915 - val_accuracy: 0.6981\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 92/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6630 - accuracy: 0.7507 - val_loss: 0.6762 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 93/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6488 - accuracy: 0.7520 - val_loss: 0.7076 - val_accuracy: 0.7033\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 94/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6612 - accuracy: 0.7463 - val_loss: 0.6706 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 95/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6602 - accuracy: 0.7450 - val_loss: 0.6587 - val_accuracy: 0.7260\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 96/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6580 - accuracy: 0.7454 - val_loss: 0.7305 - val_accuracy: 0.6998\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 97/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6569 - accuracy: 0.7415 - val_loss: 0.6803 - val_accuracy: 0.7277\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 98/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6473 - accuracy: 0.7459 - val_loss: 0.6810 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 99/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6479 - accuracy: 0.7419 - val_loss: 0.6293 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 100/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6667 - accuracy: 0.7380 - val_loss: 0.6771 - val_accuracy: 0.7190\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 101/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6576 - accuracy: 0.7502 - val_loss: 0.6540 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 102/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6489 - accuracy: 0.7424 - val_loss: 0.6895 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 103/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6490 - accuracy: 0.7515 - val_loss: 0.6623 - val_accuracy: 0.7190\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 104/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6616 - accuracy: 0.7424 - val_loss: 0.7035 - val_accuracy: 0.7277\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 105/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6580 - accuracy: 0.7437 - val_loss: 0.6691 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 106/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6292 - accuracy: 0.7450 - val_loss: 0.6759 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 107/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6907 - accuracy: 0.7389 - val_loss: 0.6519 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 108/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6785 - accuracy: 0.7389 - val_loss: 0.6864 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 109/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6743 - accuracy: 0.7385 - val_loss: 0.6811 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 110/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6794 - accuracy: 0.7324 - val_loss: 0.6495 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 111/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6573 - accuracy: 0.7467 - val_loss: 0.6811 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 112/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6561 - accuracy: 0.7459 - val_loss: 0.6640 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 113/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6699 - accuracy: 0.7406 - val_loss: 0.6781 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 114/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6582 - accuracy: 0.7463 - val_loss: 0.7169 - val_accuracy: 0.6928\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 115/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6767 - accuracy: 0.7498 - val_loss: 0.6550 - val_accuracy: 0.7347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 116/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6697 - accuracy: 0.7402 - val_loss: 0.6843 - val_accuracy: 0.7051\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 117/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6069 - accuracy: 0.7628 - val_loss: 0.6944 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 118/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6763 - accuracy: 0.7450 - val_loss: 0.6945 - val_accuracy: 0.7051\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 119/150\n",
      "36/36 [==============================] - 104s 3s/step - loss: 0.6589 - accuracy: 0.7515 - val_loss: 0.6835 - val_accuracy: 0.6998\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 120/150\n",
      "36/36 [==============================] - 98s 3s/step - loss: 0.6260 - accuracy: 0.7541 - val_loss: 0.6713 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 121/150\n",
      "36/36 [==============================] - 98s 3s/step - loss: 0.6603 - accuracy: 0.7437 - val_loss: 0.6688 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 122/150\n",
      "36/36 [==============================] - 104s 3s/step - loss: 0.6682 - accuracy: 0.7359 - val_loss: 0.6551 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 123/150\n",
      "36/36 [==============================] - 98s 3s/step - loss: 0.6601 - accuracy: 0.7476 - val_loss: 0.6869 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 124/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6440 - accuracy: 0.7598 - val_loss: 0.7097 - val_accuracy: 0.7033\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 125/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6683 - accuracy: 0.7450 - val_loss: 0.7263 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 126/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6560 - accuracy: 0.7406 - val_loss: 0.6162 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 127/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6639 - accuracy: 0.7459 - val_loss: 0.6701 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 128/150\n",
      "36/36 [==============================] - 98s 3s/step - loss: 0.6389 - accuracy: 0.7472 - val_loss: 0.6502 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 129/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6519 - accuracy: 0.7406 - val_loss: 0.6963 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 130/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6802 - accuracy: 0.7293 - val_loss: 0.6926 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 131/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6435 - accuracy: 0.7511 - val_loss: 0.6441 - val_accuracy: 0.7277\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 132/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6184 - accuracy: 0.7581 - val_loss: 0.6611 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 133/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6510 - accuracy: 0.7446 - val_loss: 0.6248 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 134/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6448 - accuracy: 0.7541 - val_loss: 0.6624 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 135/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6267 - accuracy: 0.7493 - val_loss: 0.6172 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 136/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6853 - accuracy: 0.7332 - val_loss: 0.6710 - val_accuracy: 0.7016\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 137/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6265 - accuracy: 0.7546 - val_loss: 0.6721 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 138/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6676 - accuracy: 0.7376 - val_loss: 0.6868 - val_accuracy: 0.6928\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 139/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6568 - accuracy: 0.7498 - val_loss: 0.7115 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 140/150\n",
      "36/36 [==============================] - 102s 3s/step - loss: 0.6492 - accuracy: 0.7576 - val_loss: 0.6618 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 141/150\n",
      "36/36 [==============================] - 99s 3s/step - loss: 0.6602 - accuracy: 0.7433 - val_loss: 0.6707 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 142/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6824 - accuracy: 0.7337 - val_loss: 0.6885 - val_accuracy: 0.7190\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 143/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6702 - accuracy: 0.7346 - val_loss: 0.7331 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 144/150\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6342 - accuracy: 0.7415 - val_loss: 0.6631 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 145/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6640 - accuracy: 0.7515 - val_loss: 0.6597 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 146/150\n",
      "36/36 [==============================] - 113s 3s/step - loss: 0.6605 - accuracy: 0.7515 - val_loss: 0.7245 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 147/150\n",
      "36/36 [==============================] - 112s 3s/step - loss: 0.6531 - accuracy: 0.7515 - val_loss: 0.7167 - val_accuracy: 0.6963\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 148/150\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6700 - accuracy: 0.7433 - val_loss: 0.6685 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 149/150\n",
      "36/36 [==============================] - 94s 3s/step - loss: 0.6754 - accuracy: 0.7419 - val_loss: 0.6720 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to 3.0517578125e-06.\n",
      "Epoch 150/150\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6282 - accuracy: 0.7598 - val_loss: 0.6814 - val_accuracy: 0.7138\n"
     ]
    }
   ],
   "source": [
    "model = create_nasnet_model()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    workers=6,\n",
    "    max_queue_size=100,\n",
    "    verbose=True,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "NASNet (Functional)          (None, 7, 7, 1056)        4269716   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 4228      \n",
      "=================================================================\n",
      "Total params: 4,273,944\n",
      "Trainable params: 4,228\n",
      "Non-trainable params: 4,269,716\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 10s 1s/step - loss: 1.1192 - accuracy: 0.5838\n",
      "Test Accuracy: 58.375632762908936%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.subplot(211) \n",
    "plt.plot(history.history['accuracy']) \n",
    "plt.plot(history.history['val_accuracy']) \n",
    "plt.title('model accuracy') \n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Accuracy', 'val_acc'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(212) \n",
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.tight_layout() \n",
    "plt.savefig('acc_loss.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model.predict_generator(test_generator)\n",
    "# Get most likely class\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor       0.49      0.40      0.44       100\n",
      "meningioma_tumor       0.44      0.60      0.51       115\n",
      "        no_tumor       0.73      0.66      0.69       105\n",
      " pituitary_tumor       0.84      0.70      0.76        74\n",
      "\n",
      "        accuracy                           0.58       394\n",
      "       macro avg       0.63      0.59      0.60       394\n",
      "    weighted avg       0.61      0.58      0.59       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
