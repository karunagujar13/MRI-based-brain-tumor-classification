{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "#from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"M_CNN_M1_10_20.h5\"\n",
    "IMG_ROWS, IMG_COLS = 224, 224\n",
    "INPUT_SHAPE=(224, 224, 3)\n",
    "PATH = 'data/'\n",
    "TRAIN_DATA_PATH = os.path.join(PATH, 'Training')\n",
    "TEST_DATA_PATH = os.path.join(PATH, 'Testing')\n",
    "BATCH_SIZE = 40\n",
    "NUM_EPOCHS = 150\n",
    "CLASS_MODE = 'categorical'\n",
    "COLOR_MODE = 'rgb'\n",
    "SAVE_FORMAT = 'png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['.DS_Store', 'glioma_tumor', 'meningioma_tumor', 'no_tumor',\n",
       "       'pituitary_tumor'], dtype='<U16')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_dir_list =np.sort(os.listdir(TRAIN_DATA_PATH))\n",
    "data_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_dir_list_Test =np.sort(os.listdir(TEST_DATA_PATH))\n",
    "data_dir_list_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    shear_range=0.5, \n",
    "    rescale=1./255,\n",
    "    vertical_flip=True, \n",
    "    validation_split=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2297 images belonging to 4 classes.\n",
      "Found 573 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        TRAIN_DATA_PATH,\n",
    "        target_size=(IMG_ROWS, IMG_COLS), \n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=CLASS_MODE,\n",
    "        color_mode=COLOR_MODE, \n",
    "        shuffle=True,   \n",
    "        save_format=SAVE_FORMAT, \n",
    "        subset=\"training\")\n",
    "\n",
    "\n",
    "val_generator = train_data_gen.flow_from_directory(\n",
    "    TRAIN_DATA_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    color_mode=COLOR_MODE, \n",
    "    shuffle=True,   \n",
    "    save_format=SAVE_FORMAT, \n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2297"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glioma_tumor': 0, 'meningioma_tumor': 1, 'no_tumor': 2, 'pituitary_tumor': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DATA_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    color_mode=COLOR_MODE, \n",
    "    shuffle = False,\n",
    "    seed=None,  \n",
    "    save_format=SAVE_FORMAT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_nasnet_model():\n",
    "    \n",
    "    # Base model, with weights pre-trained on ImageNet.\n",
    "    base_model = NASNetMobile(INPUT_SHAPE, weights='imagenet', include_top=False)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.8\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=False)\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'categorical_crossentropy',\n",
    "        optimizer = optimizer,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "   initial_lrate = 0.1\n",
    "   drop = 0.5\n",
    "   epochs_drop = 10.0\n",
    "   lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate\n",
    "\n",
    "lr_scheduler =keras.callbacks.LearningRateScheduler(step_decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks_list  = [lr_scheduler, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 1/150\n",
      "58/58 [==============================] - 98s 2s/step - loss: 4.1975 - accuracy: 0.4972 - val_loss: 4.0783 - val_accuracy: 0.4555\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 2/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 2.6249 - accuracy: 0.6121 - val_loss: 2.0498 - val_accuracy: 0.6091\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 3/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 2.6915 - accuracy: 0.6156 - val_loss: 1.7173 - val_accuracy: 0.6510\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 4/150\n",
      "58/58 [==============================] - 112s 2s/step - loss: 2.3237 - accuracy: 0.6596 - val_loss: 1.4564 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 5/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 2.1254 - accuracy: 0.6609 - val_loss: 1.7801 - val_accuracy: 0.6806\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 6/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 2.4579 - accuracy: 0.6587 - val_loss: 1.6255 - val_accuracy: 0.6719\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 7/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 2.6043 - accuracy: 0.6478 - val_loss: 3.0217 - val_accuracy: 0.5637\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 8/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 2.3765 - accuracy: 0.6643 - val_loss: 2.2590 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 9/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 2.4935 - accuracy: 0.6657 - val_loss: 1.5992 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 10/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.9413 - accuracy: 0.6809 - val_loss: 1.2206 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 11/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.6787 - accuracy: 0.6970 - val_loss: 1.5890 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 12/150\n",
      "58/58 [==============================] - 93s 2s/step - loss: 1.6388 - accuracy: 0.7135 - val_loss: 1.4575 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 13/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.6689 - accuracy: 0.7101 - val_loss: 1.7669 - val_accuracy: 0.6318\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 14/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.4952 - accuracy: 0.7279 - val_loss: 1.2191 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 15/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.3959 - accuracy: 0.7105 - val_loss: 1.1081 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 16/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.4769 - accuracy: 0.7005 - val_loss: 0.9655 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 17/150\n",
      "58/58 [==============================] - 93s 2s/step - loss: 1.5197 - accuracy: 0.6870 - val_loss: 1.4086 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 18/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.3072 - accuracy: 0.7140 - val_loss: 1.0261 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 19/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.3728 - accuracy: 0.6996 - val_loss: 1.1870 - val_accuracy: 0.7155\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 20/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.2830 - accuracy: 0.6979 - val_loss: 0.9773 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 21/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.1143 - accuracy: 0.7240 - val_loss: 0.8785 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 22/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.9983 - accuracy: 0.7379 - val_loss: 0.8885 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 23/150\n",
      "58/58 [==============================] - 93s 2s/step - loss: 0.9852 - accuracy: 0.7418 - val_loss: 0.9104 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 24/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.9635 - accuracy: 0.7392 - val_loss: 0.8834 - val_accuracy: 0.7051\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 25/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 1.0595 - accuracy: 0.7227 - val_loss: 1.0179 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 26/150\n",
      "58/58 [==============================] - 93s 2s/step - loss: 0.9024 - accuracy: 0.7458 - val_loss: 0.7883 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 27/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.8745 - accuracy: 0.7510 - val_loss: 0.8962 - val_accuracy: 0.6789\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 28/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.9931 - accuracy: 0.7266 - val_loss: 0.9310 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 29/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.9939 - accuracy: 0.7444 - val_loss: 0.9159 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 30/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.8658 - accuracy: 0.7401 - val_loss: 0.7614 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 31/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7947 - accuracy: 0.7545 - val_loss: 0.6885 - val_accuracy: 0.7784\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 32/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.8122 - accuracy: 0.7519 - val_loss: 0.7691 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 33/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7812 - accuracy: 0.7536 - val_loss: 0.7247 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 34/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7851 - accuracy: 0.7536 - val_loss: 0.8156 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 35/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.8015 - accuracy: 0.7545 - val_loss: 0.7263 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 36/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7457 - accuracy: 0.7579 - val_loss: 0.7923 - val_accuracy: 0.6963\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 37/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7571 - accuracy: 0.7623 - val_loss: 0.7588 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 38/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7713 - accuracy: 0.7475 - val_loss: 0.7537 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 39/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7537 - accuracy: 0.7527 - val_loss: 0.7538 - val_accuracy: 0.7417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 40/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7207 - accuracy: 0.7653 - val_loss: 0.7104 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 41/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7259 - accuracy: 0.7575 - val_loss: 0.7580 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 42/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6654 - accuracy: 0.7723 - val_loss: 0.6699 - val_accuracy: 0.7784\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 43/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7289 - accuracy: 0.7671 - val_loss: 0.7652 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 44/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6651 - accuracy: 0.7754 - val_loss: 0.7785 - val_accuracy: 0.7260\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 45/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6960 - accuracy: 0.7662 - val_loss: 0.6963 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 46/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6840 - accuracy: 0.7636 - val_loss: 0.6741 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 47/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7253 - accuracy: 0.7562 - val_loss: 0.7783 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 48/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6661 - accuracy: 0.7736 - val_loss: 0.6941 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 49/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6941 - accuracy: 0.7492 - val_loss: 0.7082 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 50/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.7090 - accuracy: 0.7562 - val_loss: 0.6773 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 51/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.6581 - accuracy: 0.7806 - val_loss: 0.6963 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 52/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6797 - accuracy: 0.7680 - val_loss: 0.6631 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 53/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6806 - accuracy: 0.7658 - val_loss: 0.6170 - val_accuracy: 0.7644\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 54/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6630 - accuracy: 0.7719 - val_loss: 0.6913 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 55/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6403 - accuracy: 0.7762 - val_loss: 0.7114 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 56/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6398 - accuracy: 0.7784 - val_loss: 0.6813 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 57/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6872 - accuracy: 0.7653 - val_loss: 0.7545 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 58/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6273 - accuracy: 0.7736 - val_loss: 0.6365 - val_accuracy: 0.7644\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 59/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6160 - accuracy: 0.7697 - val_loss: 0.6685 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 60/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6379 - accuracy: 0.7745 - val_loss: 0.6941 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 61/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6175 - accuracy: 0.7797 - val_loss: 0.6591 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 62/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.5889 - accuracy: 0.7780 - val_loss: 0.7156 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 63/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6430 - accuracy: 0.7732 - val_loss: 0.6633 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 64/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6218 - accuracy: 0.7801 - val_loss: 0.6996 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 65/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6369 - accuracy: 0.7823 - val_loss: 0.7582 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 66/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6091 - accuracy: 0.7828 - val_loss: 0.6792 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 67/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6278 - accuracy: 0.7858 - val_loss: 0.7250 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 68/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6341 - accuracy: 0.7693 - val_loss: 0.6903 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 69/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.6473 - accuracy: 0.7741 - val_loss: 0.6297 - val_accuracy: 0.7731\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 70/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6123 - accuracy: 0.7854 - val_loss: 0.6698 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 71/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6169 - accuracy: 0.7749 - val_loss: 0.7091 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 72/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.6435 - accuracy: 0.7688 - val_loss: 0.6777 - val_accuracy: 0.7277\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 73/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.6229 - accuracy: 0.7762 - val_loss: 0.6429 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 74/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6226 - accuracy: 0.7758 - val_loss: 0.6462 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 75/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.6284 - accuracy: 0.7775 - val_loss: 0.6941 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 76/150\n",
      "58/58 [==============================] - 107s 2s/step - loss: 0.6456 - accuracy: 0.7810 - val_loss: 0.6646 - val_accuracy: 0.7435\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 77/150\n",
      "58/58 [==============================] - 98s 2s/step - loss: 0.6320 - accuracy: 0.7693 - val_loss: 0.6790 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 98s 2s/step - loss: 0.6313 - accuracy: 0.7627 - val_loss: 0.6736 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 79/150\n",
      "58/58 [==============================] - 98s 2s/step - loss: 0.6286 - accuracy: 0.7797 - val_loss: 0.6459 - val_accuracy: 0.7435\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 80/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6039 - accuracy: 0.7867 - val_loss: 0.6988 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 81/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6163 - accuracy: 0.7793 - val_loss: 0.6850 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 82/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.5787 - accuracy: 0.7845 - val_loss: 0.6167 - val_accuracy: 0.7853\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 83/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6120 - accuracy: 0.7815 - val_loss: 0.6822 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 84/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6114 - accuracy: 0.7762 - val_loss: 0.6483 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 85/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.5947 - accuracy: 0.7906 - val_loss: 0.6948 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 86/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6179 - accuracy: 0.7684 - val_loss: 0.6828 - val_accuracy: 0.7574\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 87/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.5990 - accuracy: 0.7780 - val_loss: 0.7037 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 88/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6372 - accuracy: 0.7736 - val_loss: 0.6283 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 89/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6338 - accuracy: 0.7667 - val_loss: 0.6716 - val_accuracy: 0.7696\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 90/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6556 - accuracy: 0.7653 - val_loss: 0.6307 - val_accuracy: 0.7574\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 91/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6212 - accuracy: 0.7801 - val_loss: 0.6401 - val_accuracy: 0.7609\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 92/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6170 - accuracy: 0.7810 - val_loss: 0.6521 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 93/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6009 - accuracy: 0.7727 - val_loss: 0.6765 - val_accuracy: 0.7435\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 94/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6292 - accuracy: 0.7771 - val_loss: 0.6918 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 95/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6108 - accuracy: 0.7867 - val_loss: 0.6732 - val_accuracy: 0.7557\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 96/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6233 - accuracy: 0.7801 - val_loss: 0.6889 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 97/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6361 - accuracy: 0.7767 - val_loss: 0.6729 - val_accuracy: 0.7539\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 98/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.5746 - accuracy: 0.7915 - val_loss: 0.6486 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 99/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6098 - accuracy: 0.7815 - val_loss: 0.6951 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 100/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.5927 - accuracy: 0.7897 - val_loss: 0.6625 - val_accuracy: 0.7557\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 101/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6204 - accuracy: 0.7775 - val_loss: 0.6590 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 102/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6370 - accuracy: 0.7754 - val_loss: 0.6880 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 103/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6201 - accuracy: 0.7749 - val_loss: 0.6661 - val_accuracy: 0.7260\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 104/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6646 - accuracy: 0.7671 - val_loss: 0.6961 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 105/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6122 - accuracy: 0.7697 - val_loss: 0.6406 - val_accuracy: 0.7539\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 106/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6099 - accuracy: 0.7741 - val_loss: 0.7030 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 107/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6064 - accuracy: 0.7767 - val_loss: 0.6415 - val_accuracy: 0.7539\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 108/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.5841 - accuracy: 0.7949 - val_loss: 0.6535 - val_accuracy: 0.7592\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to 9.765625e-05.\n",
      "Epoch 109/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6326 - accuracy: 0.7771 - val_loss: 0.6786 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 110/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6320 - accuracy: 0.7732 - val_loss: 0.6729 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 111/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6141 - accuracy: 0.7775 - val_loss: 0.6706 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 112/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6216 - accuracy: 0.7788 - val_loss: 0.6518 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 113/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6116 - accuracy: 0.7749 - val_loss: 0.6439 - val_accuracy: 0.7557\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 114/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.6811 - accuracy: 0.7675 - val_loss: 0.6666 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 115/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.5740 - accuracy: 0.7810 - val_loss: 0.6399 - val_accuracy: 0.7557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 116/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6210 - accuracy: 0.7788 - val_loss: 0.6321 - val_accuracy: 0.7644\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 117/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6402 - accuracy: 0.7801 - val_loss: 0.6425 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 118/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6501 - accuracy: 0.7688 - val_loss: 0.7309 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to 4.8828125e-05.\n",
      "Epoch 119/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6085 - accuracy: 0.7849 - val_loss: 0.6717 - val_accuracy: 0.7574\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 120/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.5951 - accuracy: 0.7841 - val_loss: 0.6863 - val_accuracy: 0.7539\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 121/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6523 - accuracy: 0.7754 - val_loss: 0.6664 - val_accuracy: 0.7592\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 122/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6542 - accuracy: 0.7710 - val_loss: 0.6942 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 123/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6113 - accuracy: 0.7767 - val_loss: 0.6428 - val_accuracy: 0.7661\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 124/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6425 - accuracy: 0.7732 - val_loss: 0.6921 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 125/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6133 - accuracy: 0.7758 - val_loss: 0.6534 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 126/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.5883 - accuracy: 0.7889 - val_loss: 0.6965 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 127/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6481 - accuracy: 0.7736 - val_loss: 0.7240 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 128/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.5994 - accuracy: 0.7823 - val_loss: 0.6921 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to 2.44140625e-05.\n",
      "Epoch 129/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6143 - accuracy: 0.7719 - val_loss: 0.7009 - val_accuracy: 0.7557\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 130/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6356 - accuracy: 0.7706 - val_loss: 0.6788 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 131/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6324 - accuracy: 0.7771 - val_loss: 0.6743 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 132/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6113 - accuracy: 0.7875 - val_loss: 0.7027 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 133/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 0.6320 - accuracy: 0.7745 - val_loss: 0.6939 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 134/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6008 - accuracy: 0.7845 - val_loss: 0.7087 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 135/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6075 - accuracy: 0.7723 - val_loss: 0.6358 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 136/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6420 - accuracy: 0.7754 - val_loss: 0.6302 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 137/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6102 - accuracy: 0.7823 - val_loss: 0.6653 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 138/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.6282 - accuracy: 0.7714 - val_loss: 0.6913 - val_accuracy: 0.7435\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to 1.220703125e-05.\n",
      "Epoch 139/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6223 - accuracy: 0.7749 - val_loss: 0.6991 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 140/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.5878 - accuracy: 0.7810 - val_loss: 0.6451 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 141/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6472 - accuracy: 0.7736 - val_loss: 0.6763 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 142/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6084 - accuracy: 0.7793 - val_loss: 0.6359 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 143/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6104 - accuracy: 0.7862 - val_loss: 0.6482 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 144/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.5998 - accuracy: 0.7902 - val_loss: 0.6860 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 145/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6262 - accuracy: 0.7801 - val_loss: 0.6669 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 146/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6233 - accuracy: 0.7675 - val_loss: 0.6847 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 147/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6013 - accuracy: 0.7836 - val_loss: 0.6547 - val_accuracy: 0.7661\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 148/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.5944 - accuracy: 0.7819 - val_loss: 0.6427 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to 6.103515625e-06.\n",
      "Epoch 149/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6746 - accuracy: 0.7623 - val_loss: 0.6872 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to 3.0517578125e-06.\n",
      "Epoch 150/150\n",
      "58/58 [==============================] - 94s 2s/step - loss: 0.6163 - accuracy: 0.7723 - val_loss: 0.6350 - val_accuracy: 0.7469\n"
     ]
    }
   ],
   "source": [
    "model = create_nasnet_model()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    workers=6,\n",
    "    max_queue_size=100,\n",
    "    verbose=True,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "NASNet (Functional)          (None, 7, 7, 1056)        4269716   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 4228      \n",
      "=================================================================\n",
      "Total params: 4,273,944\n",
      "Trainable params: 4,228\n",
      "Non-trainable params: 4,269,716\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 11s 1s/step - loss: 1.3680 - accuracy: 0.5863\n",
      "Test Accuracy: 58.629441261291504%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.subplot(211) \n",
    "plt.plot(history.history['accuracy']) \n",
    "plt.plot(history.history['val_accuracy']) \n",
    "plt.title('model accuracy') \n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Accuracy', 'val_acc'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(212) \n",
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.tight_layout() \n",
    "plt.savefig('acc_loss_50.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
