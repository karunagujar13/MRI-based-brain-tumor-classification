{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "#from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"M_CNN_M1_10_20.h5\"\n",
    "IMG_ROWS, IMG_COLS = 224, 224\n",
    "INPUT_SHAPE=(224, 224, 3)\n",
    "PATH = 'data/'\n",
    "TRAIN_DATA_PATH = os.path.join(PATH, 'Training')\n",
    "TEST_DATA_PATH = os.path.join(PATH, 'Testing')\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "CLASS_MODE = 'categorical'\n",
    "COLOR_MODE = 'rgb'\n",
    "SAVE_FORMAT = 'png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['.DS_Store', 'glioma_tumor', 'meningioma_tumor', 'no_tumor',\n",
       "       'pituitary_tumor'], dtype='<U16')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_dir_list =np.sort(os.listdir(TRAIN_DATA_PATH))\n",
    "data_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_dir_list_Test =np.sort(os.listdir(TEST_DATA_PATH))\n",
    "data_dir_list_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    brightness_range=[0.6, 0.9],\n",
    "    zoom_range=[0.5,1.5],\n",
    "    rescale=1./255,\n",
    "    vertical_flip=True, \n",
    "    validation_split=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2297 images belonging to 4 classes.\n",
      "Found 573 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        TRAIN_DATA_PATH,\n",
    "        target_size=(IMG_ROWS, IMG_COLS), \n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=CLASS_MODE,\n",
    "        color_mode=COLOR_MODE, \n",
    "        shuffle=True,   \n",
    "        save_format=SAVE_FORMAT, \n",
    "        subset=\"training\")\n",
    "\n",
    "\n",
    "val_generator = train_data_gen.flow_from_directory(\n",
    "    TRAIN_DATA_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    color_mode=COLOR_MODE, \n",
    "    shuffle=True,   \n",
    "    save_format=SAVE_FORMAT, \n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2297"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glioma_tumor': 0, 'meningioma_tumor': 1, 'no_tumor': 2, 'pituitary_tumor': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DATA_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    color_mode=COLOR_MODE, \n",
    "    shuffle = False,\n",
    "    seed=None,  \n",
    "    save_format=SAVE_FORMAT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_nasnet_model():\n",
    "    \n",
    "    # Base model, with weights pre-trained on ImageNet.\n",
    "    base_model = NASNetMobile(INPUT_SHAPE, weights='imagenet', include_top=False)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.8\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=False)\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'categorical_crossentropy',\n",
    "        optimizer = optimizer,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "   initial_lrate = 0.1\n",
    "   drop = 0.5\n",
    "   epochs_drop = 10.0\n",
    "   lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate\n",
    "\n",
    "lr_scheduler =keras.callbacks.LearningRateScheduler(step_decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks_list  = [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# labels_dict : {ind_label: count_label}\n",
    "# mu : parameter to tune \n",
    "\n",
    "def create_class_weight(labels_dict,mu=0.15):\n",
    "    total = sum(labels_dict.values())\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "    for key in keys:\n",
    "        score = (mu*total)/float(labels_dict[key])\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight\n",
    "\n",
    "# random labels_dict\n",
    "labels_dict = {0: 826, 1: 822, 2: 395, 3: 827}\n",
    "\n",
    "class_wt = create_class_weight(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 98s 3s/step - loss: 3.1123 - accuracy: 0.4763 - val_loss: 1.7293 - val_accuracy: 0.5079\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.9062 - accuracy: 0.5825 - val_loss: 1.2432 - val_accuracy: 0.6003\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 2.0090 - accuracy: 0.5816 - val_loss: 1.9909 - val_accuracy: 0.5236\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 2.0124 - accuracy: 0.5825 - val_loss: 1.5188 - val_accuracy: 0.6108\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 2.2965 - accuracy: 0.5777 - val_loss: 3.1063 - val_accuracy: 0.4223\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 2.1866 - accuracy: 0.5977 - val_loss: 1.2587 - val_accuracy: 0.6719\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.8761 - accuracy: 0.6313 - val_loss: 1.6404 - val_accuracy: 0.5812\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.9234 - accuracy: 0.6025 - val_loss: 1.5199 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 2.1618 - accuracy: 0.6021 - val_loss: 1.3994 - val_accuracy: 0.6475\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.5871 - accuracy: 0.6491 - val_loss: 1.1375 - val_accuracy: 0.6370\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.5163 - accuracy: 0.6430 - val_loss: 1.0626 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.4522 - accuracy: 0.6356 - val_loss: 0.8492 - val_accuracy: 0.7155\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.1972 - accuracy: 0.6739 - val_loss: 0.9202 - val_accuracy: 0.6911\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.2799 - accuracy: 0.6495 - val_loss: 1.1452 - val_accuracy: 0.6283\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.1652 - accuracy: 0.6643 - val_loss: 0.9141 - val_accuracy: 0.7155\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.2605 - accuracy: 0.6465 - val_loss: 0.9525 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.1278 - accuracy: 0.6761 - val_loss: 1.0240 - val_accuracy: 0.6318\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.1127 - accuracy: 0.6591 - val_loss: 0.8947 - val_accuracy: 0.6911\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.2102 - accuracy: 0.6408 - val_loss: 1.4663 - val_accuracy: 0.5462\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.0510 - accuracy: 0.6657 - val_loss: 0.9622 - val_accuracy: 0.6440\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.0058 - accuracy: 0.6791 - val_loss: 0.8377 - val_accuracy: 0.6981\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.9402 - accuracy: 0.6857 - val_loss: 0.8029 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.8753 - accuracy: 0.7000 - val_loss: 0.7550 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.9243 - accuracy: 0.6800 - val_loss: 0.8297 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.9203 - accuracy: 0.6896 - val_loss: 0.7737 - val_accuracy: 0.7051\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8691 - accuracy: 0.6887 - val_loss: 0.8573 - val_accuracy: 0.6649\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.8413 - accuracy: 0.7044 - val_loss: 0.8167 - val_accuracy: 0.6702\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8734 - accuracy: 0.6835 - val_loss: 0.7949 - val_accuracy: 0.6771\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 29/100\n",
      " 2/36 [>.............................] - ETA: 49s - loss: 0.6506 - accuracy: 0.7656"
     ]
    }
   ],
   "source": [
    "model = create_nasnet_model()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    workers=6,\n",
    "    max_queue_size=100,\n",
    "    verbose=True,\n",
    "    callbacks=callbacks_list,\n",
    "    #class_weight = class_wt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.subplot(211) \n",
    "plt.plot(history.history['accuracy']) \n",
    "plt.plot(history.history['val_accuracy']) \n",
    "plt.title('model accuracy') \n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Accuracy', 'val_acc'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(212) \n",
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.tight_layout() \n",
    "plt.savefig('acc_loss_50.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
