{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "#from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"M_CNN_M1_10_20.h5\"\n",
    "IMG_ROWS, IMG_COLS = 224, 224\n",
    "INPUT_SHAPE=(224, 224, 3)\n",
    "PATH = 'data/'\n",
    "TRAIN_DATA_PATH = os.path.join(PATH, 'Training')\n",
    "TEST_DATA_PATH = os.path.join(PATH, 'Testing')\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "CLASS_MODE = 'categorical'\n",
    "COLOR_MODE = 'rgb'\n",
    "SAVE_FORMAT = 'png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['.DS_Store', 'glioma_tumor', 'meningioma_tumor', 'no_tumor',\n",
       "       'pituitary_tumor'], dtype='<U16')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_dir_list =np.sort(os.listdir(TRAIN_DATA_PATH))\n",
    "data_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_dir_list_Test =np.sort(os.listdir(TEST_DATA_PATH))\n",
    "data_dir_list_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    brightness_range=[0.6, 0.9],\n",
    "    zoom_range=[0.5,1.5],\n",
    "    rescale=1./255,\n",
    "    vertical_flip=True, \n",
    "    validation_split=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2297 images belonging to 4 classes.\n",
      "Found 573 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        TRAIN_DATA_PATH,\n",
    "        target_size=(IMG_ROWS, IMG_COLS), \n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=CLASS_MODE,\n",
    "        color_mode=COLOR_MODE, \n",
    "        shuffle=True,   \n",
    "        save_format=SAVE_FORMAT, \n",
    "        subset=\"training\")\n",
    "\n",
    "\n",
    "val_generator = train_data_gen.flow_from_directory(\n",
    "    TRAIN_DATA_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    color_mode=COLOR_MODE, \n",
    "    shuffle=True,   \n",
    "    save_format=SAVE_FORMAT, \n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2297"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glioma_tumor': 0, 'meningioma_tumor': 1, 'no_tumor': 2, 'pituitary_tumor': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DATA_PATH,\n",
    "    target_size=(IMG_ROWS, IMG_COLS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    color_mode=COLOR_MODE, \n",
    "    shuffle = False,\n",
    "    seed=None,  \n",
    "    save_format=SAVE_FORMAT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_nasnet_model():\n",
    "    \n",
    "    # Base model, with weights pre-trained on ImageNet.\n",
    "    base_model = NASNetMobile(INPUT_SHAPE, weights='imagenet', include_top=False)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.8\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=False)\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'categorical_crossentropy',\n",
    "        optimizer = optimizer,\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "   initial_lrate = 0.1\n",
    "   drop = 0.5\n",
    "   epochs_drop = 10.0\n",
    "   lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate\n",
    "\n",
    "lr_scheduler =keras.callbacks.LearningRateScheduler(step_decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks_list  = [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# labels_dict : {ind_label: count_label}\n",
    "# mu : parameter to tune \n",
    "\n",
    "def create_class_weight(labels_dict,mu=0.15):\n",
    "    total = sum(labels_dict.values())\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "    for key in keys:\n",
    "        score = (mu*total)/float(labels_dict[key])\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight\n",
    "\n",
    "# random labels_dict\n",
    "labels_dict = {0: 826, 1: 822, 2: 395, 3: 827}\n",
    "\n",
    "class_wt = create_class_weight(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 98s 3s/step - loss: 3.6819 - accuracy: 0.4732 - val_loss: 1.4490 - val_accuracy: 0.5794\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 2.3397 - accuracy: 0.5586 - val_loss: 1.2456 - val_accuracy: 0.6213\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 2.1960 - accuracy: 0.5764 - val_loss: 1.1500 - val_accuracy: 0.6143\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.9338 - accuracy: 0.5799 - val_loss: 1.6437 - val_accuracy: 0.5358\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.9407 - accuracy: 0.6030 - val_loss: 2.7798 - val_accuracy: 0.5445\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.9282 - accuracy: 0.6134 - val_loss: 2.0636 - val_accuracy: 0.5742\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.9522 - accuracy: 0.6082 - val_loss: 1.0648 - val_accuracy: 0.6998\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 97s 3s/step - loss: 1.9942 - accuracy: 0.6195 - val_loss: 1.4521 - val_accuracy: 0.6510\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.9837 - accuracy: 0.6043 - val_loss: 1.7401 - val_accuracy: 0.5497\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.5794 - accuracy: 0.6452 - val_loss: 1.6091 - val_accuracy: 0.6318\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.5147 - accuracy: 0.6452 - val_loss: 2.3363 - val_accuracy: 0.4677\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 98s 3s/step - loss: 1.4534 - accuracy: 0.6504 - val_loss: 0.9740 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.2464 - accuracy: 0.6578 - val_loss: 0.9307 - val_accuracy: 0.6702\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.2274 - accuracy: 0.6587 - val_loss: 1.3109 - val_accuracy: 0.6475\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.2047 - accuracy: 0.6604 - val_loss: 0.9423 - val_accuracy: 0.6719\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.1175 - accuracy: 0.6700 - val_loss: 0.9170 - val_accuracy: 0.6387\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.1860 - accuracy: 0.6548 - val_loss: 0.8830 - val_accuracy: 0.6963\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.1657 - accuracy: 0.6587 - val_loss: 0.8973 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.05.\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 1.0644 - accuracy: 0.6761 - val_loss: 0.8719 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.0085 - accuracy: 0.6839 - val_loss: 0.8317 - val_accuracy: 0.6859\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.9656 - accuracy: 0.6839 - val_loss: 0.8139 - val_accuracy: 0.6876\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 1.0143 - accuracy: 0.6731 - val_loss: 0.8173 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.9615 - accuracy: 0.6774 - val_loss: 0.8549 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.9392 - accuracy: 0.6909 - val_loss: 0.8670 - val_accuracy: 0.6789\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.9503 - accuracy: 0.6892 - val_loss: 1.0262 - val_accuracy: 0.5707\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.8819 - accuracy: 0.7022 - val_loss: 0.7467 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.8711 - accuracy: 0.6939 - val_loss: 0.7750 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.9254 - accuracy: 0.6752 - val_loss: 1.0129 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.8645 - accuracy: 0.6935 - val_loss: 0.8191 - val_accuracy: 0.6771\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8102 - accuracy: 0.7088 - val_loss: 0.7798 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8160 - accuracy: 0.6970 - val_loss: 0.7877 - val_accuracy: 0.6719\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.8065 - accuracy: 0.7035 - val_loss: 0.7485 - val_accuracy: 0.6911\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8045 - accuracy: 0.7035 - val_loss: 0.7743 - val_accuracy: 0.6894\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8080 - accuracy: 0.7170 - val_loss: 0.7806 - val_accuracy: 0.6754\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7851 - accuracy: 0.7079 - val_loss: 0.7494 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.8137 - accuracy: 0.6922 - val_loss: 0.7088 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7902 - accuracy: 0.7031 - val_loss: 0.7610 - val_accuracy: 0.6981\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7745 - accuracy: 0.7140 - val_loss: 0.7697 - val_accuracy: 0.6824\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7749 - accuracy: 0.7101 - val_loss: 0.7996 - val_accuracy: 0.6649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7273 - accuracy: 0.7262 - val_loss: 0.7293 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7487 - accuracy: 0.7305 - val_loss: 0.7676 - val_accuracy: 0.7016\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7435 - accuracy: 0.7092 - val_loss: 0.7320 - val_accuracy: 0.6963\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7364 - accuracy: 0.7214 - val_loss: 0.6890 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.7704 - accuracy: 0.7140 - val_loss: 0.7339 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7071 - accuracy: 0.7305 - val_loss: 0.7338 - val_accuracy: 0.6771\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7375 - accuracy: 0.7349 - val_loss: 0.7373 - val_accuracy: 0.6754\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7419 - accuracy: 0.7101 - val_loss: 0.7410 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7211 - accuracy: 0.7283 - val_loss: 0.7390 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.00625.\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7502 - accuracy: 0.7305 - val_loss: 0.7080 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7467 - accuracy: 0.7179 - val_loss: 0.7587 - val_accuracy: 0.6998\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7158 - accuracy: 0.7262 - val_loss: 0.7282 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6819 - accuracy: 0.7379 - val_loss: 0.7506 - val_accuracy: 0.6859\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7300 - accuracy: 0.7327 - val_loss: 0.7449 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7094 - accuracy: 0.7405 - val_loss: 0.7798 - val_accuracy: 0.6963\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6997 - accuracy: 0.7410 - val_loss: 0.7170 - val_accuracy: 0.7016\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7336 - accuracy: 0.7227 - val_loss: 0.7140 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7402 - accuracy: 0.7153 - val_loss: 0.7245 - val_accuracy: 0.6911\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7556 - accuracy: 0.7162 - val_loss: 0.7389 - val_accuracy: 0.6702\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.003125.\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7284 - accuracy: 0.7240 - val_loss: 0.7314 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6818 - accuracy: 0.7379 - val_loss: 0.7309 - val_accuracy: 0.7051\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7095 - accuracy: 0.7310 - val_loss: 0.7098 - val_accuracy: 0.7295\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7151 - accuracy: 0.7353 - val_loss: 0.7151 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7292 - accuracy: 0.7305 - val_loss: 0.7028 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7191 - accuracy: 0.7310 - val_loss: 0.6936 - val_accuracy: 0.7260\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7318 - accuracy: 0.7013 - val_loss: 0.7028 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6987 - accuracy: 0.7362 - val_loss: 0.7649 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6906 - accuracy: 0.7323 - val_loss: 0.7326 - val_accuracy: 0.6859\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7253 - accuracy: 0.7205 - val_loss: 0.6985 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 0.0015625.\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6920 - accuracy: 0.7296 - val_loss: 0.7506 - val_accuracy: 0.6859\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 100s 3s/step - loss: 0.6990 - accuracy: 0.7323 - val_loss: 0.6932 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7231 - accuracy: 0.7249 - val_loss: 0.7182 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7094 - accuracy: 0.7188 - val_loss: 0.7049 - val_accuracy: 0.6963\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7173 - accuracy: 0.7249 - val_loss: 0.7134 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7049 - accuracy: 0.7288 - val_loss: 0.7003 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7402 - accuracy: 0.7170 - val_loss: 0.7229 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6795 - accuracy: 0.7397 - val_loss: 0.7407 - val_accuracy: 0.6859\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7088 - accuracy: 0.7405 - val_loss: 0.7200 - val_accuracy: 0.7016\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00078: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7093 - accuracy: 0.7253 - val_loss: 0.7238 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 0.00078125.\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7044 - accuracy: 0.7209 - val_loss: 0.7312 - val_accuracy: 0.6981\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6862 - accuracy: 0.7288 - val_loss: 0.6946 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6999 - accuracy: 0.7340 - val_loss: 0.7308 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7091 - accuracy: 0.7305 - val_loss: 0.7628 - val_accuracy: 0.6876\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7048 - accuracy: 0.7201 - val_loss: 0.7568 - val_accuracy: 0.6928\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 97s 3s/step - loss: 0.6882 - accuracy: 0.7279 - val_loss: 0.7299 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7047 - accuracy: 0.7179 - val_loss: 0.6991 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7100 - accuracy: 0.7257 - val_loss: 0.6956 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 99s 3s/step - loss: 0.6961 - accuracy: 0.7296 - val_loss: 0.7167 - val_accuracy: 0.7155\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7220 - accuracy: 0.7162 - val_loss: 0.7274 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 0.000390625.\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6684 - accuracy: 0.7353 - val_loss: 0.7155 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6998 - accuracy: 0.7340 - val_loss: 0.6977 - val_accuracy: 0.6981\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6939 - accuracy: 0.7423 - val_loss: 0.6426 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6908 - accuracy: 0.7283 - val_loss: 0.7057 - val_accuracy: 0.7016\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7232 - accuracy: 0.7257 - val_loss: 0.7120 - val_accuracy: 0.7086\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6939 - accuracy: 0.7249 - val_loss: 0.7643 - val_accuracy: 0.6702\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.6622 - accuracy: 0.7392 - val_loss: 0.6872 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 95s 3s/step - loss: 0.7183 - accuracy: 0.7318 - val_loss: 0.7141 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 99s 3s/step - loss: 0.6772 - accuracy: 0.7266 - val_loss: 0.7417 - val_accuracy: 0.6998\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.7047 - accuracy: 0.7344 - val_loss: 0.6995 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 0.0001953125.\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.7104 - accuracy: 0.7353"
     ]
    }
   ],
   "source": [
    "model = create_nasnet_model()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    workers=6,\n",
    "    max_queue_size=100,\n",
    "    verbose=True,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight = class_wt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.subplot(211) \n",
    "plt.plot(history.history['accuracy']) \n",
    "plt.plot(history.history['val_accuracy']) \n",
    "plt.title('model accuracy') \n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Accuracy', 'val_acc'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(212) \n",
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.tight_layout() \n",
    "plt.savefig('acc_loss_50.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
